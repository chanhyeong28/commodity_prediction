{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08878c5c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-05T05:37:00.766007Z",
     "iopub.status.busy": "2025-09-05T05:37:00.765751Z",
     "iopub.status.idle": "2025-09-05T05:37:02.246350Z",
     "shell.execute_reply": "2025-09-05T05:37:02.245566Z"
    },
    "papermill": {
     "duration": 1.485364,
     "end_time": "2025-09-05T05:37:02.247809",
     "exception": false,
     "start_time": "2025-09-05T05:37:00.762445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mitsui-commodity-prediction-challenge/target_pairs.csv\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/train_labels.csv\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/train.csv\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/test.csv\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/lagged_test_labels/test_labels_lag_1.csv\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/lagged_test_labels/test_labels_lag_4.csv\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/lagged_test_labels/test_labels_lag_3.csv\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/lagged_test_labels/test_labels_lag_2.csv\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/mitsui_inference_server.py\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/mitsui_gateway.py\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/__init__.py\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/core/templates.py\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/core/base_gateway.py\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/core/relay.py\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/core/kaggle_evaluation.proto\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/core/__init__.py\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/core/generated/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b1c8e24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T05:37:02.253071Z",
     "iopub.status.busy": "2025-09-05T05:37:02.252721Z",
     "iopub.status.idle": "2025-09-05T05:37:08.126204Z",
     "shell.execute_reply": "2025-09-05T05:37:08.125405Z"
    },
    "papermill": {
     "duration": 5.87753,
     "end_time": "2025-09-05T05:37:08.127774",
     "exception": false,
     "start_time": "2025-09-05T05:37:02.250244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "import logging\n",
    "import time\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e54b6131",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T05:37:08.132831Z",
     "iopub.status.busy": "2025-09-05T05:37:08.132367Z",
     "iopub.status.idle": "2025-09-05T05:37:08.135760Z",
     "shell.execute_reply": "2025-09-05T05:37:08.135240Z"
    },
    "papermill": {
     "duration": 0.006945,
     "end_time": "2025-09-05T05:37:08.136796",
     "exception": false,
     "start_time": "2025-09-05T05:37:08.129851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18106569",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T05:37:08.141104Z",
     "iopub.status.busy": "2025-09-05T05:37:08.140899Z",
     "iopub.status.idle": "2025-09-05T05:37:08.143777Z",
     "shell.execute_reply": "2025-09-05T05:37:08.143302Z"
    },
    "papermill": {
     "duration": 0.006213,
     "end_time": "2025-09-05T05:37:08.144825",
     "exception": false,
     "start_time": "2025-09-05T05:37:08.138612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3ce725a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T05:37:08.149280Z",
     "iopub.status.busy": "2025-09-05T05:37:08.149051Z",
     "iopub.status.idle": "2025-09-05T05:37:08.152116Z",
     "shell.execute_reply": "2025-09-05T05:37:08.151588Z"
    },
    "papermill": {
     "duration": 0.006508,
     "end_time": "2025-09-05T05:37:08.153161",
     "exception": false,
     "start_time": "2025-09-05T05:37:08.146653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = [f'target_{i}' for i in range(424)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3546095",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T05:37:08.157464Z",
     "iopub.status.busy": "2025-09-05T05:37:08.157259Z",
     "iopub.status.idle": "2025-09-05T05:37:08.160635Z",
     "shell.execute_reply": "2025-09-05T05:37:08.160105Z"
    },
    "papermill": {
     "duration": 0.006647,
     "end_time": "2025-09-05T05:37:08.161614",
     "exception": false,
     "start_time": "2025-09-05T05:37:08.154967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'n_estimators': 30,\n",
    "    'early_stopping_rounds': 10,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'device': 'gpu',\n",
    "    'gpu_platform_id': 0,\n",
    "    'gpu_device_id': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3784c51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T05:37:08.166604Z",
     "iopub.status.busy": "2025-09-05T05:37:08.166406Z",
     "iopub.status.idle": "2025-09-05T05:37:08.193380Z",
     "shell.execute_reply": "2025-09-05T05:37:08.192827Z"
    },
    "papermill": {
     "duration": 0.030574,
     "end_time": "2025-09-05T05:37:08.194349",
     "exception": false,
     "start_time": "2025-09-05T05:37:08.163775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    def __init__(self):\n",
    "        logger.info(\"Initializing Predictor\")\n",
    "        start_time = time.time()\n",
    "        self.input_dir = '/kaggle/input/mitsui-commodity-prediction-challenge/'\n",
    "        self.output_dir = '/kaggle/working/'\n",
    "        \n",
    "        try:\n",
    "            logger.info(\"Loading input files\")\n",
    "            self.train = pd.read_csv(os.path.join(self.input_dir, 'train.csv'))\n",
    "            self.train_labels = pd.read_csv(os.path.join(self.input_dir, 'train_labels.csv'))\n",
    "            self.target_pairs = pd.read_csv(os.path.join(self.input_dir, 'target_pairs.csv'))\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load input files: {e}\")\n",
    "            raise\n",
    "\n",
    "        logger.info(\"Processing target pairs\")\n",
    "        self.target_pairs['pair'] = self.target_pairs['pair'].fillna('')\n",
    "        self.target_pairs['asset1'] = self.target_pairs['pair'].apply(lambda x: x.split(' - ')[0] if ' - ' in x else x)\n",
    "        self.target_pairs['asset2'] = self.target_pairs['pair'].apply(lambda x: x.split(' - ')[1] if ' - ' in x else np.nan)\n",
    "        self.assets = set(self.target_pairs['asset1'].unique()) | set(self.target_pairs['asset2'].dropna().unique())\n",
    "        \n",
    "        logger.info(\"Adding features to training data\")\n",
    "        self.history = self.add_features(self.train.copy())\n",
    "        self.history_labels = self.train_labels.copy()\n",
    "        \n",
    "        self.submissions = []\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        model_path = os.path.join(self.output_dir, 'models.pkl')\n",
    "        if os.path.exists(model_path):\n",
    "            logger.info(\"Loading pre-trained models\")\n",
    "            self.models = joblib.load(model_path)\n",
    "        else:\n",
    "            logger.info(\"Training models\")\n",
    "            self.models = self.train_models()\n",
    "            logger.info(\"Saving pre-trained models\")\n",
    "            joblib.dump(self.models, model_path)\n",
    "        \n",
    "        logger.info(\"Caching scaled training features\")\n",
    "        df = pd.merge(self.history, self.history_labels, on='date_id', how='inner')\n",
    "        X = df.drop(columns=['date_id'] + target_cols, errors='ignore')\n",
    "        X = X.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        self.X_scaled = pd.DataFrame(self.scaler.fit_transform(X), columns=X.columns)\n",
    "        \n",
    "        logger.info(f\"Predictor initialization completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    def add_features(self, df, is_test=False):\n",
    "        logger.info(f\"Adding features to {'test' if is_test else 'training'} DataFrame\")\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            df['dow'] = df['date_id'] % 7\n",
    "            df['month'] = df['date_id'] // 30 % 12\n",
    "            \n",
    "            for idx, row in self.target_pairs.iterrows():\n",
    "                asset1, asset2, lag = row['asset1'], row['asset2'], row['lag']\n",
    "                if asset1 in df.columns:\n",
    "                    price1 = df[asset1].replace(0, np.nan)\n",
    "                    df[f'{asset1}_ret1'] = np.log(price1 / price1.shift(1)).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "                    df[f'{asset1}_ret{lag}'] = np.log(price1 / price1.shift(lag)).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "                    for w in [5, 10]:\n",
    "                        df[f'{asset1}_ma{w}'] = df[f'{asset1}_ret1'].rolling(w).mean().fillna(0)\n",
    "                        df[f'{asset1}_std{w}'] = df[f'{asset1}_ret1'].rolling(w).std().fillna(0)\n",
    "                \n",
    "                if pd.notna(asset2) and asset2 in df.columns:\n",
    "                    price2 = df[asset2].replace(0, np.nan)\n",
    "                    df[f'{asset2}_ret1'] = np.log(price2 / price2.shift(1)).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "                    df[f'{asset2}_ret{lag}'] = np.log(price2 / price2.shift(lag)).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "                    for w in [5, 10]:\n",
    "                        df[f'{asset2}_ma{w}'] = df[f'{asset2}_ret1'].rolling(w).mean().fillna(0)\n",
    "                        df[f'{asset2}_std{w}'] = df[f'{asset2}_ret1'].rolling(w).std().fillna(0)\n",
    "                    \n",
    "                    if asset1 in df.columns and asset2 in df.columns:\n",
    "                        df[f'spread_{asset1}_{asset2}'] = np.log(price1 / price2).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "                        df[f'spread_ret1_{asset1}_{asset2}'] = df[f'{asset1}_ret1'] - df[f'{asset2}_ret1']\n",
    "            \n",
    "            price_cols = [col for col in df.columns if any(k in col for k in ['Close', 'adj_close', 'Open', 'settlement_price'])]\n",
    "            if price_cols:\n",
    "                df['global_avg_ret'] = df[[f'{c}_ret1' for c in price_cols if f'{c}_ret1' in df.columns]].mean(axis=1).fillna(0)\n",
    "                df['global_std_ret'] = df[[f'{c}_ret1' for c in price_cols if f'{c}_ret1' in df.columns]].std(axis=1).fillna(0)\n",
    "            \n",
    "            df = df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "            logger.info(f\"Feature engineering completed in {time.time() - start_time:.2f} seconds\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to add features: {e}\")\n",
    "            raise\n",
    "\n",
    "    def train_models(self):\n",
    "        logger.info(\"Merging history and labels for training\")\n",
    "        try:\n",
    "            df = pd.merge(self.history, self.history_labels, on='date_id', how='inner')\n",
    "            \n",
    "            X = df.drop(columns=['date_id'] + target_cols, errors='ignore')\n",
    "            y = df[target_cols].fillna(0)\n",
    "            \n",
    "            X = X.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "            \n",
    "            logger.info(\"Scaling features\")\n",
    "            X_scaled = pd.DataFrame(self.scaler.fit_transform(X), columns=X.columns)\n",
    "            \n",
    "            train_size = int(0.8 * len(X_scaled))\n",
    "            X_train, X_val = X_scaled[:train_size], X_scaled[train_size:]\n",
    "            y_train, y_val = y[:train_size], y[train_size:]\n",
    "            \n",
    "            models = {}\n",
    "            for col in tqdm(target_cols, desc=\"Training models\"):\n",
    "                try:\n",
    "                    model = lgb.LGBMRegressor(**params)\n",
    "                    model.fit(\n",
    "                        X_train, y_train[col],\n",
    "                        eval_set=[(X_val, y_val[col])],\n",
    "                        eval_metric='rmse',\n",
    "                        callbacks=[lgb.early_stopping(10, verbose=False)]\n",
    "                    )\n",
    "                    models[col] = model\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Failed to train model for {col}: {e}\")\n",
    "                    raise\n",
    "            return models\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to train models: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_lagged_labels(self, label_lags_1_batch, label_lags_2_batch, label_lags_3_batch, label_lags_4_batch):\n",
    "        logger.info(\"Processing lagged labels\")\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            lagged_dfs = [df for df in [label_lags_1_batch, label_lags_2_batch, label_lags_3_batch, label_lags_4_batch] if not df.is_empty()]\n",
    "            if not lagged_dfs:\n",
    "                logger.info(\"No lagged labels provided\")\n",
    "                return pd.DataFrame()\n",
    "            \n",
    "            for i, df in enumerate(lagged_dfs, 1):\n",
    "                logger.info(f\"Lagged DataFrame {i} columns: {df.columns}\")\n",
    "            \n",
    "            expected_cols = ['date_id'] + target_cols\n",
    "            aligned_dfs = []\n",
    "            for df in lagged_dfs:\n",
    "                if 'release_date_id' in df.columns:\n",
    "                    df = df.rename({'release_date_id': 'date_id'})\n",
    "                \n",
    "                df_cols = set(df.columns)\n",
    "                missing_cols = set(expected_cols) - df_cols\n",
    "                extra_cols = df_cols - set(expected_cols)\n",
    "                \n",
    "                logger.info(f\"Missing columns in DataFrame: {missing_cols}\")\n",
    "                logger.info(f\"Extra columns in DataFrame: {extra_cols}\")\n",
    "                \n",
    "                if extra_cols:\n",
    "                    df = df.drop(list(extra_cols))\n",
    "                \n",
    "                for col in missing_cols:\n",
    "                    df = df.with_columns(pl.lit(0.0).alias(col))\n",
    "                \n",
    "                df = df.select(expected_cols)\n",
    "                aligned_dfs.append(df)\n",
    "            \n",
    "            if aligned_dfs:\n",
    "                lagged_df = pl.concat(aligned_dfs, how='vertical')\n",
    "                lagged_df = lagged_df.sort('date_id').unique(subset=['date_id'])\n",
    "                logger.info(f\"Final lagged DataFrame columns: {lagged_df.columns}\")\n",
    "            else:\n",
    "                lagged_df = pl.DataFrame(columns=expected_cols)\n",
    "            \n",
    "            logger.info(f\"Lagged labels processing completed in {time.time() - start_time:.2f} seconds\")\n",
    "            return lagged_df.to_pandas()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to process lagged labels: {e}\")\n",
    "            raise\n",
    "\n",
    "    def predict(self, test: pl.DataFrame, label_lags_1_batch: pl.DataFrame, label_lags_2_batch: pl.DataFrame, \n",
    "                label_lags_3_batch: pl.DataFrame, label_lags_4_batch: pl.DataFrame) -> pl.DataFrame:\n",
    "        logger.info(\"Starting prediction\")\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            test_df = test.to_pandas()\n",
    "            test_df = test_df.drop(['is_scored'], axis=1, errors='ignore')\n",
    "            \n",
    "            logger.info(\"Adding features to test data\")\n",
    "            test_df = self.add_features(test_df, is_test=True)\n",
    "            \n",
    "            new_labels = self.get_lagged_labels(label_lags_1_batch, label_lags_2_batch, label_lags_3_batch, label_lags_4_batch)\n",
    "            if not new_labels.empty:\n",
    "                logger.info(\"New lagged labels received, updating history_labels\")\n",
    "                self.history_labels = pd.concat([self.history_labels, new_labels], ignore_index=True)\n",
    "                self.history_labels = self.history_labels.sort_values('date_id').drop_duplicates('date_id')\n",
    "            \n",
    "            current_date = test_df['date_id'].iloc[0]\n",
    "            X_test = test_df[test_df['date_id'] == current_date].drop(columns=['date_id'], errors='ignore')\n",
    "            X_test = X_test.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "            \n",
    "            logger.info(\"Scaling test features\")\n",
    "            X_test_scaled = pd.DataFrame(self.scaler.transform(X_test), columns=X_test.columns)\n",
    "            \n",
    "            logger.info(\"Making predictions\")\n",
    "            preds = {col: model.predict(X_test_scaled)[0] for col, model in self.models.items()}\n",
    "            \n",
    "            sub_for_save = pl.DataFrame({'date_id': [current_date], **preds})\n",
    "            self.submissions.append(sub_for_save.to_pandas())\n",
    "            \n",
    "            logger.info(\"Saving submission to parquet\")\n",
    "            submission_df = pd.concat(self.submissions, ignore_index=True)\n",
    "            submission_df.to_parquet(os.path.join(self.output_dir, 'submission.parquet'), index=False)\n",
    "            \n",
    "            sub = pl.DataFrame(preds)\n",
    "            logger.info(f\"Prediction DataFrame columns: {sub.columns}\")\n",
    "            logger.info(f\"Prediction completed in {time.time() - start_time:.2f} seconds\")\n",
    "            return sub\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Prediction failed: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e0619a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T05:37:08.198713Z",
     "iopub.status.busy": "2025-09-05T05:37:08.198514Z",
     "iopub.status.idle": "2025-09-05T06:02:50.011650Z",
     "shell.execute_reply": "2025-09-05T06:02:50.010802Z"
    },
    "papermill": {
     "duration": 1541.817122,
     "end_time": "2025-09-05T06:02:50.013348",
     "exception": false,
     "start_time": "2025-09-05T05:37:08.196226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:   0%|          | 0/424 [00:00<?, ?it/s]1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "Training models: 100%|██████████| 424/424 [14:01<00:00,  1.99s/it]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from kaggle_evaluation.mitsui_inference_server import MitsuiInferenceServer\n",
    "    logger.info(\"Starting main execution\")\n",
    "    try:\n",
    "        predictor = Predictor()\n",
    "        inference_server = MitsuiInferenceServer(predictor.predict)\n",
    "        if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "            logger.info(\"Running inference server in competition mode\")\n",
    "            inference_server.serve()\n",
    "        else:\n",
    "            logger.info(\"Running local gateway\")\n",
    "            inference_server.run_local_gateway(('/kaggle/input/mitsui-commodity-prediction-challenge/',))\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to start inference server: {e}\")\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 13613251,
     "sourceId": 94771,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1554.48048,
   "end_time": "2025-09-05T06:02:51.255873",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-05T05:36:56.775393",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
